{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Statistical learning final project**: dataset selection and preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Daniel A.\n",
    "### UID: 100444499"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pycountry\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Prior to importing the data, I have matches with the following regex: \\\"\\s\\[[\\w\\S]{1,}\\]\\\", in order to remove some tags that the world bank databank adds to their columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the raw data\n",
    "raw_data = pd.read_csv('./data/raw/wb_raw_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial modifications and selection of range of rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# excluding aggregates\n",
    "codes_to_exclude = raw_data.iloc[2593:2640,3].values\n",
    "\n",
    "# filtering the dataset\n",
    "data = raw_data[~(raw_data['Country Code'].isin(codes_to_exclude))] \n",
    "\n",
    "# removing final diagnostic columns\n",
    "data = data[~(data['Time'].isna()) & ~(data['Time Code'].isna())]\n",
    "\n",
    "# converting year column to integer\n",
    "data['Time'] = data['Time'].astype(int)\n",
    "\n",
    "# replacing .. with NAN as the raw data indends this to be a NAN\n",
    "data = data.replace('..',np.nan)\n",
    "\n",
    "# sorting values\n",
    "data = data.sort_values(['Time','Country Name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Years imported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2002 2004 2005 2008 2010 2012 2013 2015 2018 2020]\n"
     ]
    }
   ],
   "source": [
    "# checking years we have queried\n",
    "years = data.Time.unique()\n",
    "print(years)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filling NAs with previous year's data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making a dictionary with the subsets of the main dataframe\n",
    "dfs = {}\n",
    "for year in years:\n",
    "    dfs[year] = data[data['Time'] == year].reset_index(drop=True)\n",
    "\n",
    "# replacing nans in the 2020 dataframe with previous years data, as \n",
    "# the previous years' data still serves us a purpose for the analysis\n",
    "for year in years:   \n",
    "    dfs[2020] = dfs[2020].fillna(dfs[year])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing columns with more than 45 NAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing columns where there's too many NANs\n",
    "cols_to_keep = []\n",
    "df = {}\n",
    "for col,val in zip(dfs[2020].columns,dfs[2020].isna().sum()):\n",
    "    if val < 45:\n",
    "        cols_to_keep.append(col)\n",
    "df = dfs[2020][cols_to_keep]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing life expectancy as it is a component of HDI (our target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing life exp\n",
    "df.drop(\"Life expectancy at birth, total (years)\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing countries with more than 4 NAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking which countries have the most NANs\n",
    "all_countries = df['Country Name'].values\n",
    "countries_removed = []\n",
    "for country,val in zip(all_countries,df.isna().sum(axis=1)):\n",
    "    # removing at 3 nans per row\n",
    "    if val > 4:\n",
    "        countries_removed.append(country)\n",
    "\n",
    "# finally filtering to remove them\n",
    "# either way, these countries are mostly dependencies or \n",
    "# complex countries to get data from, like North Korea\n",
    "# so even after imputing, this would probably\n",
    "# yield unrealistic values\n",
    "df = df[~(df['Country Name'].isin(countries_removed))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtaining HDI per country from Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping the wikipedia page for list of countries by human development index\n",
    "hdis_page = requests.get('https://en.wikipedia.org/wiki/List_of_countries_by_Human_Development_Index').text\n",
    "soup = BeautifulSoup(hdis_page,'lxml')\n",
    "\n",
    "\n",
    "# get the HDI table\n",
    "table = soup.find('table',{'class':'wikitable sortable'})\n",
    "links = table.findAll('a')\n",
    "tds = table.findAll('td')\n",
    "countries, hdis = [], []\n",
    "\n",
    "# going through the links to find the countries wikipedia has data for\n",
    "for link in links:\n",
    "    countries.append(link.get('title'))\n",
    "\n",
    "# cleaning countriesif not string\n",
    "countries = [x for x in countries if x != None]\n",
    "\n",
    "# finding the HDIs and appending them to the list hdi\n",
    "for td in tds:\n",
    "    try:\n",
    "        num = float(td.text)\n",
    "        if str(num)[0:2] == '0.':\n",
    "            hdis.append(num)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "# making a dict with the values\n",
    "countries = {cont:['',hdi] for cont,hdi in zip(countries,hdis)}\n",
    "\n",
    "# using the same approach for the codes for easier matching later on\n",
    "codes_page = requests.get('https://en.wikipedia.org/wiki/ISO_3166-1_alpha-3').text\n",
    "soup = BeautifulSoup(codes_page,'lxml')\n",
    "\n",
    "# get the codes table\n",
    "table = soup.find('div',{'class':'plainlist'})\n",
    "# scrape list elements and add them to the dict\n",
    "lis = table.findAll('li')\n",
    "li_lists = []\n",
    "for li in lis:\n",
    "    try:\n",
    "        countries[li.find('a').get('title')][0] = li.find('span').text\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "# making the values tuples\n",
    "countries = {cont:tuple(val) for cont,val in countries.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding HDI to the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding the HDI to the dataframe for the countries which we have in the wikipedia list\n",
    "df['HDI'] = np.nan\n",
    "matched_countries = []\n",
    "missing_codes = []\n",
    "for code,hdi in countries.values():\n",
    "    df.loc[df['Country Code'] == code,'HDI'] = hdi\n",
    "\n",
    "# finally keepiTRUEng this dataframe\n",
    "df = df[df['Country Code'].isin([x[0] for x in countries.values()])].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixing columns' types and names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modifying columns that are supposed to be numeric\n",
    "cols = list(set(list(df.columns)) - set(['index', 'Time', 'Time Code', 'Country Name', 'Country Code']))\n",
    "for col in cols:\n",
    "    df[col] = df[col].astype(float)\n",
    "\n",
    "# new column names\n",
    "colnames = ['year','year_code','country_name',\n",
    "            'country_code','gdp','foreign_inv_inflows',\n",
    "            'exports_perc_gdp','inflation_perc',\n",
    "            'education_years','education_perc_gdp','gds_perc_gdp',\n",
    "            'gross_savings_perc_gdp','int_tourism_arrivals',\n",
    "            'int_tourism_receipts','gni','perc_internet_users',\n",
    "            'hdi']\n",
    "\n",
    "# original colnames : colnames dict\n",
    "col_dict = dict(zip(df.columns,colnames))\n",
    "\n",
    "# renaming columns as the names are too long\n",
    "df.columns = colnames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing categorical target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to construct target variable\n",
    "def hdi(x):\n",
    "    conds = {\n",
    "        'very high':x >= 0.8,\n",
    "        'high':x >= 0.7 and x <= 0.799,\n",
    "        'medium':x >= 0.55 and x <= 0.699,\n",
    "        'low':x <0.55\n",
    "    }\n",
    "    for cat,cond in conds.items(): \n",
    "        if cond == True:\n",
    "            return cat \n",
    "\n",
    "df['hdi_cat'] = df['hdi'].apply(lambda x: hdi(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting the data from Python into R to impute the few missing values left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the dataset before imputing\n",
    "df.to_csv('./data/preproc_outputs/data_before_imp.csv')\n",
    "\n",
    "# dumping the col information into a json\n",
    "col_dict['Human development index as a category (1-4)'] = 'hdi_cat'\n",
    "\n",
    "with open('./data/preproc_outputs/columns.json','w') as f:\n",
    "    f.write(json.dumps(col_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Attaching package: ‘mice’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:stats’:\n",
      "\n",
      "    filter\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:base’:\n",
      "\n",
      "    cbind, rbind\n",
      "\n",
      "\n",
      "Warning message:\n",
      "“Number of logged events: 6”\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " iter imp variable\n",
      "  1   1  foreign_inv_inflows  exports_perc_gdp  inflation_perc  education_years  education_perc_gdp  gds_perc_gdp  gross_savings_perc_gdp  int_tourism_arrivals  int_tourism_receipts\n",
      "  1   2  foreign_inv_inflows  exports_perc_gdp  inflation_perc  education_years  education_perc_gdp  gds_perc_gdp  gross_savings_perc_gdp  int_tourism_arrivals  int_tourism_receipts\n",
      "  1   3  foreign_inv_inflows  exports_perc_gdp  inflation_perc  education_years  education_perc_gdp  gds_perc_gdp  gross_savings_perc_gdp  int_tourism_arrivals  int_tourism_receipts\n",
      "  1   4  foreign_inv_inflows  exports_perc_gdp  inflation_perc  education_years  education_perc_gdp  gds_perc_gdp  gross_savings_perc_gdp  int_tourism_arrivals  int_tourism_receipts\n",
      "  1   5  foreign_inv_inflows  exports_perc_gdp  inflation_perc  education_years  education_perc_gdp  gds_perc_gdp  gross_savings_perc_gdp  int_tourism_arrivals  int_tourism_receipts\n",
      "  2   1  foreign_inv_inflows  exports_perc_gdp  inflation_perc  education_years  education_perc_gdp  gds_perc_gdp  gross_savings_perc_gdp  int_tourism_arrivals  int_tourism_receipts\n",
      "  2   2  foreign_inv_inflows  exports_perc_gdp  inflation_perc  education_years  education_perc_gdp  gds_perc_gdp  gross_savings_perc_gdp  int_tourism_arrivals  int_tourism_receipts\n",
      "  2   3  foreign_inv_inflows  exports_perc_gdp  inflation_perc  education_years  education_perc_gdp  gds_perc_gdp  gross_savings_perc_gdp  int_tourism_arrivals  int_tourism_receipts\n",
      "  2   4  foreign_inv_inflows  exports_perc_gdp  inflation_perc  education_years  education_perc_gdp  gds_perc_gdp  gross_savings_perc_gdp  int_tourism_arrivals  int_tourism_receipts\n",
      "  2   5  foreign_inv_inflows  exports_perc_gdp  inflation_perc  education_years  education_perc_gdp  gds_perc_gdp  gross_savings_perc_gdp  int_tourism_arrivals  int_tourism_receipts\n",
      "  3   1  foreign_inv_inflows  exports_perc_gdp  inflation_perc  education_years  education_perc_gdp  gds_perc_gdp  gross_savings_perc_gdp  int_tourism_arrivals  int_tourism_receipts\n",
      "  3   2  foreign_inv_inflows  exports_perc_gdp  inflation_perc  education_years  education_perc_gdp  gds_perc_gdp  gross_savings_perc_gdp  int_tourism_arrivals  int_tourism_receipts\n",
      "  3   3  foreign_inv_inflows  exports_perc_gdp  inflation_perc  education_years  education_perc_gdp  gds_perc_gdp  gross_savings_perc_gdp  int_tourism_arrivals  int_tourism_receipts\n",
      "  3   4  foreign_inv_inflows  exports_perc_gdp  inflation_perc  education_years  education_perc_gdp  gds_perc_gdp  gross_savings_perc_gdp  int_tourism_arrivals  int_tourism_receipts\n",
      "  3   5  foreign_inv_inflows  exports_perc_gdp  inflation_perc  education_years  education_perc_gdp  gds_perc_gdp  gross_savings_perc_gdp  int_tourism_arrivals  int_tourism_receipts\n",
      "  4   1  foreign_inv_inflows  exports_perc_gdp  inflation_perc  education_years  education_perc_gdp  gds_perc_gdp  gross_savings_perc_gdp  int_tourism_arrivals  int_tourism_receipts\n",
      "  4   2  foreign_inv_inflows  exports_perc_gdp  inflation_perc  education_years  education_perc_gdp  gds_perc_gdp  gross_savings_perc_gdp  int_tourism_arrivals  int_tourism_receipts\n",
      "  4   3  foreign_inv_inflows  exports_perc_gdp  inflation_perc  education_years  education_perc_gdp  gds_perc_gdp  gross_savings_perc_gdp  int_tourism_arrivals  int_tourism_receipts\n",
      "  4   4  foreign_inv_inflows  exports_perc_gdp  inflation_perc  education_years  education_perc_gdp  gds_perc_gdp  gross_savings_perc_gdp  int_tourism_arrivals  int_tourism_receipts\n",
      "  4   5  foreign_inv_inflows  exports_perc_gdp  inflation_perc  education_years  education_perc_gdp  gds_perc_gdp  gross_savings_perc_gdp  int_tourism_arrivals  int_tourism_receipts\n",
      "  5   1  foreign_inv_inflows  exports_perc_gdp  inflation_perc  education_years  education_perc_gdp  gds_perc_gdp  gross_savings_perc_gdp  int_tourism_arrivals  int_tourism_receipts\n",
      "  5   2  foreign_inv_inflows  exports_perc_gdp  inflation_perc  education_years  education_perc_gdp  gds_perc_gdp  gross_savings_perc_gdp  int_tourism_arrivals  int_tourism_receipts\n",
      "  5   3  foreign_inv_inflows  exports_perc_gdp  inflation_perc  education_years  education_perc_gdp  gds_perc_gdp  gross_savings_perc_gdp  int_tourism_arrivals  int_tourism_receipts\n",
      "  5   4  foreign_inv_inflows  exports_perc_gdp  inflation_perc  education_years  education_perc_gdp  gds_perc_gdp  gross_savings_perc_gdp  int_tourism_arrivals  int_tourism_receipts\n",
      "  5   5  foreign_inv_inflows  exports_perc_gdp  inflation_perc  education_years  education_perc_gdp  gds_perc_gdp  gross_savings_perc_gdp  int_tourism_arrivals  int_tourism_receipts\n"
     ]
    }
   ],
   "source": [
    "# importing mice library to impute the data\n",
    "library(mice)\n",
    "\n",
    "# reading the csv outputted earlier in the IRkernel to impute the data\n",
    "df <- read.csv('./data/preproc_outputs/data_before_imp.csv')\n",
    "df <- df[,2:length(names(df))]\n",
    "\n",
    "# instantiating the imputer and imputing the data\n",
    "imp = mice(df, m = 5, method = \"cart\")\n",
    "df = complete(imp)\n",
    "\n",
    "# saving csv for reference\n",
    "write.csv(df,'./data/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.3"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}